{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c7f6b4",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PaHenriquez/448_Artificial_Intelligence/blob/main/Assignment4.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d025c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and pip instllations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a5884",
   "metadata": {},
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71ca6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "    target  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      0.0  \n",
       "8      0.0  \n",
       "9      0.0  \n",
       "10     0.0  \n",
       "11     0.0  \n",
       "12     0.0  \n",
       "13     0.0  \n",
       "14     0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data = np.c_[iris['data'], iris['target']], columns = iris['feature_names'] + ['target'] )\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3018476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856bf54",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "\n",
    "\n",
    "The data contains measurements of different part(sepal and petal) of the flowers. These categories of sizes are consider the features while the species column is the label as the species column acts as the flower identifier and it is what we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d9ba9",
   "metadata": {},
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acf1777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "\n",
    "\n",
    "x = iris.data;\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8aa9db",
   "metadata": {},
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f34c7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class =  setosa\n",
      "prob =  83.72 %\n",
      "\n",
      "predicted class =  versicolor\n",
      "prob =  94.95 %\n",
      "\n",
      "predicted class =  virginica\n",
      "prob =  99.89 %\n",
      "\n",
      "log_reg classifier on test set accuracy =  1.0 \n",
      "\n",
      "intercept =  [  9.5009535    1.91217986 -11.41313336] \n",
      "\n",
      "coefficient =  [[-0.42670783  0.97265174 -2.44461361 -1.03195011]\n",
      " [ 0.51309747 -0.22372275 -0.21510929 -0.85156146]\n",
      " [-0.08638964 -0.74892899  2.6597229   1.88351157]]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "\n",
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "species_pred_prob = log_reg.predict_proba(x_test)\n",
    "\n",
    "classes = iris.target_names\n",
    "\n",
    "for class_name, prob in zip(classes, species_pred_prob):\n",
    "    i = np.argmax(prob)\n",
    "    print('predicted class = ',class_name)\n",
    "    print('prob = ',round(prob[i]*100,2),'%\\n')\n",
    "    \n",
    "\n",
    "\n",
    "score = log_reg.score(x_test, y_test)\n",
    "print('log_reg classifier on test set accuracy = ', score ,'\\n')\n",
    "\n",
    "\n",
    "print('intercept = ', log_reg.intercept_ ,'\\n')\n",
    "print('coefficient = ', log_reg.coef_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd53b1a",
   "metadata": {},
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fd4f5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class = setosa and accuracy = 91.5%\n",
      "predicted class = versicolor and accuracy = 95.24%\n",
      "predicted class = virginica and accuracy = 98.23%\n",
      "Accuracy of SVC on test set = 1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "\n",
    "\n",
    "svc = svm.SVC(probability = True)\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "y_pred_prob_svc = svc.predict_proba(x_test)\n",
    "\n",
    "for class_name, prob in zip (classes, y_pred_prob_svc):\n",
    "    i = np.argmax(prob)\n",
    "    print(f'predicted class = {class_name} and accuracy = {round(prob[i]*100,2)}%')\n",
    "    \n",
    "score = svc.score(x_test,y_test)\n",
    "print(f\"Accuracy of SVC on test set = {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17393e65",
   "metadata": {},
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed92fd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class = setosa and accuracy = 90.47%\n",
      "predicted class = versicolor and accuracy = 99.81%\n",
      "predicted class = virginica and accuracy = 99.95%\n",
      "Accuracy of Neural Network with test set = 1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "\n",
    "\n",
    "mlp_model = MLPClassifier(solver = 'sgd', hidden_layer_sizes = 8, max_iter = 600, learning_rate_init = 0.01)\n",
    "\n",
    "mlp_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred_prob_mlp = mlp_model.predict_proba(x_test)\n",
    "\n",
    "for class_name, prob in zip(classes, y_pred_prob_mlp):\n",
    "    i = np.argmax(prob)\n",
    "    print(f'predicted class = {class_name} and accuracy = {round(prob[i]*100,2)}%')\n",
    "    \n",
    "score = mlp_model.score(x_test, y_test)\n",
    "print(f'Accuracy of Neural Network with test set = {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c73ba4",
   "metadata": {},
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50645c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class = setosa and accuracy = 100.0%\n",
      "predicted class = versicolor and accuracy = 100.0%\n",
      "predicted class = virginica and accuracy = 100.0%\n",
      "Accuracy of K-neighbors on test set = 1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "\n",
    "\n",
    "K_nearest_neighbors = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "K_nearest_neighbors.fit(x_train, y_train)\n",
    "\n",
    "y_pred_prob_knn = K_nearest_neighbors.predict_proba(x_test)\n",
    "\n",
    "for class_name, prob  in zip(classes, y_pred_prob_knn):\n",
    "    i = np.argmax(prob)\n",
    "    print(f'predicted class = {class_name} and accuracy = {prob[i]*100}%')\n",
    "    \n",
    "    \n",
    "score = K_nearest_neighbors.score(x_test,y_test)\n",
    "print('Accuracy of K-neighbors on test set = {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc39e05",
   "metadata": {},
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dc1b1",
   "metadata": {},
   "source": [
    "Different types of classification models were used to take the data of the different measurement feature of the plant in order to create a prediction of how the plant would be classified in terms of those measurements known. Betwen the 4 classifactions model done, the best was K neartest neighbors model as not only the accuracy is 100% but it was able to predict each class of iris plant at 100%.\n",
    "\n",
    "One thing that suprise me about the exercise was the accuracy on the model and whether how the data was splits effected the results of the 4 following models or the chosen paramaters for the models caused this overly high accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
